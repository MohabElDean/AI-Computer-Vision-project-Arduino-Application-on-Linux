{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_CLASS = 2\n",
    "IMAGE_SIZE = (400, 400)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "def load_data(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path, filename))\n",
    "        img = cv2.resize(img, IMAGE_SIZE)  # Resize images to a consistent size\n",
    "        images.append(img)\n",
    "        labels.append(path.split('/')[-1])  # Assuming the label is the name of the directory\n",
    "    return images, labels\n",
    "\n",
    "def test_image(model, image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)  # Resize image to match training data size\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    prediction = model.predict(img)\n",
    "    if np.argmax(prediction) == 0:\n",
    "        print(\"Detected object: Apple\")\n",
    "    else:\n",
    "        print(\"Detected object: Banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "apple_path = \"C:/Users/zuzz4/OneDrive/Desktop/data new/train/Apple\"\n",
    "banana_path = \"C:/Users/zuzz4/OneDrive/Desktop/data new/train/Banana\"\n",
    "test_path = \"C:/Users/zuzz4/OneDrive/Desktop/data new/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "apple_images, apple_labels = load_data(apple_path)\n",
    "banana_images, banana_labels = load_data(banana_path)\n",
    "\n",
    "# Combine data and labels\n",
    "images = np.array(apple_images + banana_images)\n",
    "labels = np.array(apple_labels + banana_labels)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_dict = {'Apple': 0, 'Banana': 1}\n",
    "labels = np.array([label_dict[label] for label in labels])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(400, 400, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Checkpoint to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(\"feed_forward_nn_model.keras\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=35, batch_size=32, validation_data=(X_test, y_test), callbacks=[checkpoint])\n",
    "\n",
    "# Print test accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def capture_and_save_image(folder_path):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Open the default camera (usually 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open camera\")\n",
    "        return\n",
    "\n",
    "    # Allow the camera to adjust to the lighting conditions (1-second delay)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the captured frame\n",
    "    cv2.imshow('Captured Image', frame)\n",
    "    \n",
    "    # Save the image to the specified folder path\n",
    "    image_path = os.path.join(folder_path, 'captured_image.jpg')\n",
    "    cv2.imwrite(image_path, frame)\n",
    "    \n",
    "    print(\"Image saved successfully at:\", image_path)\n",
    "\n",
    "    # Release the camera and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Specify the folder path where the image will be saved\n",
    "folder_path = r\"D:\\colledge\\4th year\\second semester\\AI\\indivudual project\\dataset\\tesst\"\n",
    "\n",
    "# Call the function to capture and save the image\n",
    "capture_and_save_image(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images using tf.keras.preprocessing.image_dataset_from_directory\n",
    "test_dataset_path = \"C:/Users/zuzz4/OneDrive/Desktop/data new/Test\"\n",
    "test_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dataset_path,\n",
    "    labels=None,\n",
    "    color_mode='rgb',\n",
    "    label_mode=None,\n",
    "    shuffle=False,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Cell\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test images\n",
    "print(\"\\nPredictions on test images:\")\n",
    "for images in test_images:\n",
    "    result = model.predict(images)\n",
    "    print(result)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
